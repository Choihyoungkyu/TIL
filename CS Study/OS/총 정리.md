# 총 정리



## 1. System Structure & Program Execution



#### 운영체제(Operating System, OS)

- 컴퓨터 하드웨어 바로 위에 설치되어 사용자 및 다른 모든 소프트웨어와 하드웨어를 연결하는 소프트웨어 계층
  - 협의의 운영체제(커널) : 운영체제의 핵심 부분으로 메모리에 상주하는 부분
  - 광의의 운영체제 : 커널 뿐 아니라 각종 주변 시스템 유틸리티를 포함한 개념



#### 운영체제의 목적

- 컴퓨터 시스템의 **자원을 효율적으로 관리**
- 컴퓨터 시스템을 편리하게 사용할 수 있는 **환경 제공**
- 즉, 사용자의 요청에 대해 빠르고 정확하게 시스템 자원을 제공하고 많은 양의 데이터를 처리해주기 위해 필요



#### 운영체제의 역할

- 프로세스 관리
  - 프로세스의 생성, 제거, 중지, 재시작, 동기화
  - 프로세스간 통신
  - 교착상태 방지 기법 등을 제공
- 기억장치 관리
  - 주기억장치 이용 프로세스 파악
  - 주기억장치에 프로세스를 적제 및 회수
- 입출력장치 관리
  - 입출력장치의 상태 파악
  - 입출력장치 스케줄링
- 정보 관리
  - 파일 생성 및 제거
  - 파일 & 디렉토리 관리



#### 컴퓨터 시스템 구조

- 컴퓨터 : CPU + Memory
- I/O device : 하드디스크(보조기억장치), 모니터, 키보드, 프린터 등등



#### Mode bit

- 0일 때(OS가 CPU를 가지고 있을 때) : 다 가능 (**interrupt가 들어오면 CPU가 OS에게 넘어감**)
- 1일 때(사용자 프로그램이 CPU를 가지고 있을 때) : 한정된 instruction만 실행 가능

CPU는 일반적으로 사용자 프로그램을 순차적으로 수행(mode bit == 1)
만약, 사용자 프로그램에서 I/O device에 접근을 해야 하는 경우 ---> system call
==> 의도적으로 interrupt line을 설정해 CPU가 멈추게 하고, OS한테 CPU를 넘겨줌(mode bit = 0)



#### 동기식 입출력과 비동기식 입출력

- I/O는 커널을 통해서만 가능
- 동기식 입출력 (synchronous I/O)
  - I/O 요청 후 입출력 작업이 완료된 후에야 제어가 사용자 프로그램에 넘어감
- 비동기식 입출력 (asynchronous I/O)
  - I/O가 시작된 후 입출력 작업이 끝나기를 기다리지 않고 제어가 사용자 프로그램에 즉시 넘어감



#### DMA (Direct Memory Access)

- 빠른 입출력 장치를 메모리에 가까운 속도로 처리하기 위해 사용
- CPU의 중재 없이 device controller가 device의 buffer storage의 내용을 메모리에 block 단위로 직접 전송
- 바이트 단위가 아니라 block 단위로 인터럽트를 발생시킴



#### 커널 주소 공간의 내용

- code
  - 시스템콜, 인터럽트 처리 코드
  - 자원 관리를 위한 코드
  - 편리한 서비스 제공을 위한 코드
- data
  - Table(Data Structure) - Object(Hardware or Software)
- stack
  - Process A의 커널 스택

---



## 2. Process



#### 프로세스의 상태 (Process State)

- **Running**
  - CPU를 잡고 instruction을 수행중인 상태
- **Ready**
  - CPU를 기다리는 상태(메모리 등 다른 조건을 모두 만족하고)
- **Blocked (wait, sleep)**
  - CPU를 주어도 당장 instruction을 수행할 수 없는 상태
  - Process 자신이 요청한 event(예 : I/O)가 즉시 만족되지 않아 이를 기다리는 상태
  - ex) 디스크에서 file을 읽어와야 하는 경우
- **Suspended (stopped)** 
  - 외부적인 이유로 프로세스의 수행이 정지된 상태
  - 프로세스는 통째로 디스크에 swap out 된다
  - ex)
    - 사용자가 프로그램을 일시 정지 시킨 경우 (break key)
    - 시스템이 여러 이유로 프로세스를 잠시 중단 시킨 경우 (메모리에 너무 많은 프로세스가 올라와 있을 때)

- **New**
  - 프로세스가 생성중인 상태
- **Terminated**
  - 수행(execution)이 끝난 상태 --> 정리할게 남아 있는 상태
  - Blocked 와 차이점 
    - Blocked는 자신이 요청한 event가 만족되면 Ready
    - Suspended는 외부에서 resume 해주어야 Active



#### PCB (Process Control Block)

- 운영체제가 각 프로세스를 관리하기 위해 프로세스당 유지하는 정보
  1. OS가 관리상 사용하는 정보
     - Process state, Process ID
     - scheduling information, priority
  2. CPU 수행 관련 하드웨어 값
     - Program counter, registers
  3. 메모리 관련
     - code, data, stack의 위치 정보
  4. 파일 관련
     - Open file descriptors



#### 문맥 교환 (Context Switch)

- CPU를 한 프로세스에서 다른 프로세스로 넘겨주는 과정
- CPU가 다른 프로세스에게 넘어갈 때 운영체제는 다음을 수행
  - CPU를 내어주는 프로세스의 상태를 그 프로세스의 PCB에 저장
  - CPU를 새롭게 얻는 프로세스의 상태를 PCB에서 읽어옴
- System call이나 Interrupt 발생 시 반드시 context switch가 일어나는 것은 아님



#### 프로세스 스케줄링 큐

- Job queue
  - 현재 시스템 내에 있는 모든 프로세스의 집합
- Ready queue (CPU를 기다리는 줄)
  - 현재 메모리 내에 있으면서 CPU를 잡아서 실행되기를 기다리는 프로세스의 집합
- Device queues
  - I/O device의 처리를 기다리는 프로세스의 집합



#### 스케줄러 (Scheduler)

- Long-term scheduler (장기 스케줄러 or job scheduler)
  - 시작 프로세스 중 어떤 것들을 **ready queue**로 보낼지 결정
  - 프로세스에 **memory** 및 각종 자원을 주는 문제
  - degree of Multiprogramming을 제어
  - time sharing system에는 보통 장기 스케줄러가 없음 (무조건 ready)
- Short-term scheduler (단기 스케줄러 or CPU scheduler)
  - 어떤 프로세스를 다음번에 running 시킬지 결정
  - 프로세스에 **CPU**를 주는 문제
  - 충분히 빨라야 함 (millisecond 단위)
- Medium-Term scheduler (중기 스케줄러 or Swapper)
  - 여유 공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫓아냄
  - 프로세스에게서 **memory**를 뺏는 문제 --> Suspended 상태가 됨
  - degree of Multiprogramming을 제어



#### Thread

- 다중 스레드로 구성된 태스크 구조에서는 하나의 서버 스레드가 blocked (waiting) 상태인 동안에도 동일한 태스크 내의 다른 스레드가 실행(running)되어 빠른 처리를 할 수 있다.
- 동일한 일을 수행하는 다중 스레드가 협력하여 높은 처리율(throughput)과 성능 향상을 얻을 수 있다
- 스레드를 사용하면 병렬성을 높일 수 있다  (CPU가 여러개 달린 컴퓨터에서만 가능)



#### Thread 사용의 장점

- 반응성 (Responsiveness)
  - eg) multi-threaded Web
    - if one thread is blocked (eg network) another thread continues (eg display)
- 자원 공유 (Resource Sharing)
  - n threads can share binary code, data, resource of the process
- 경제성 (Economy)
  - creating & CPU switching thread (rather than a process)
    (process를 생성하고 process를 스위칭하는 것보다 훨씬 빠름)
- 유용성 (Utilization of MP(Multi Processor : CPU가 여러개) Architectures)
  - each thread may be running in parallel on a different processor

---



## 3. Process Management & CPU Scheduling



#### 프로세스 생성

- 부모 프로세스가 자식 프로세스를 생성
  - 자신의 메모리(코드, 데이터, 스택), CPU의 문맥(PCB)까지 복사
- 일반적으로 부모가 프로세스를 생성하고 나면 서로 경쟁관계가 되어 자원을 공유하지 않음



#### 프로세스의 종료

- 자발적 종료
  - 마지막 statement 수행 후 exit() 시스템 콜을 통해
  - 프로그램에 명시적으로 적어주지 않아도 main 함수가 리턴되는 위치에 컴파일러가 넣어줌
- 비자발적 종료
  - 부모 프로세스가 자식 프로세스를 강제 종료시킴
    - 자식 프로세스가 한계치를 넘어서는 자원 요청 -> 욕심부리면 죽임
    - 자식에게 할당된 태스크가 더 이상 필요하지 않음 -> 무쓸모면 죽임
  - 키보드로 kill, break 등을 친 경우
  - 부모가 종료하는 경우
    - 부모 프로세스가 종료하기 전에 자식들이 먼저 종료됨



#### CPU Scheduler & Dispatcher -> 각각 OS 내의 코드

- CPU Scheduler
  - OS 안에서 스케줄링을 해주는 코드
  - Ready 상태의 프로세스 중에서 이번 CPU를 줄 프로세스를 선택 (단기 스케줄러(?))
- Dispatcher
  - CPU의 제어권을 CPU scheduler에 의해 선택된 프로세스에게 제공
  - 이 과정을 Context Switch (문맥 교환)라고 한다
- CPU 스케줄링이 필요한 경우
  1. Running -> Blocked (eg I/O 요청하는 시스템 콜)
  2. Running -> Ready (eg 할당시간만료로 timer interrupt)
  3. Blocked -> Ready (eg I/O 완료 후 인터럽트)
  4. Terminate (eg 프로세스 종료)
- Nonpreemptive : 강제로 빼앗지 않고 자진 반납 (1, 4번)
- Preemptive : 강제로 빼앗음 (나머지) --> 현재 많이 씀



#### Scheduling Criteria : Performance Index (= 성능 척도)

- **시스템 입장**에서의 성능 척도

  - **CPU utilization(이용률)** ---> 주방장의 순수 일한 시간
    - keep the CPU as busy as possible
  - **Throughput(처리량)** ---> 먹고 나간 손님의 총 수
    - `#` of processes that complete their execution per time unit

- **프로세스 입장**에서의 성능 척도

  - **Turnaround time(소요시간, 반환시간)** ---> 손님이 들어와서 나갈때까지의 시간

    - amount of time to execute a particular process

  - **Waiting time(대기시간)** ---> 손님이 코스요리를 먹을 경우 음식을 기다리는 총 시간

    - amount of time a process has been waiting in the ready queue
    - 선점형(preemptive)일 경우 CPU를 뺏겼다가 다시 잡는 대기시간까지 합한게 대기시간

  - **Response time(응답시간)** ---> 손님이 코스요리를 먹을 경우 첫 음식이 나오기까지의 시간

    - amount of time it takes from when a request was submitted until the first response is producted. not output (for time-sharing environment)

    - 처음 CPU를 받을 때까지 걸린 시간



#### Scheduling Algorithms

- FCFS (First-Come First-Served)
- SJF ( Shortest-Job-First)
  - 일종의 priority scheduling
  - 각 프로세스의 다음번 CPU burst time을 가지고 스케줄링에 활용
  - Preemptive일 경우
    - 현재 수행중인 프로세스의 남은 burst time보다 더 짧은 CPU burst time을 가지는 새로운 프로세스가 도착하면 CPU를 뺏김
    - 이 방법을 Shortest-Remaining-Time-First (SRTF)라고 부름
  - 문제점
    - starvation(기아 현상)
    - 다음번 CPU burst를 알 수 없다 -> 과거의 CPU burst time을 이용해서 추정(exponential averaging)

- Priority Scheduling
  - highest priority를 가진 프로세스에게 CPU를 할당
  - 문제점 : Starvation
  - 해결책 : Aging - as time progresses increase the priority of the process
- Round Robin (RR)
  - 각 프로세스는 동일한 크기의 할당시간(time quantum)을 가지고, 할당 시간이 지나면 프로세스는 선점(preempted) 당하고 ready queue의 젤 뒤에 다시 줄을 섬
  - 할당시간(q)이 크면 --> FCFS
  - 할당시간(q)가 작으면 --> context switch 오버헤드가 커진다
  - 일반적으로 SJF보다 average turnaround time(소요 시간)이 길지만 response time(응답 시간)은 짧다
- Multilevel Queue
  - Ready queue를 여러 개로 분할
    - foreground (interactive) - **RR**
    - background (batch - no human interaction) - **FCFS**
  - 큐에 대한 스케줄링이 필요
    - **Fixed priority scheduling**
      - foreground가 다 차면 background로
      - Possibility of starvation
    - **Time slice**
      - 각 큐에 CPU time을 적절한 비율로 할당
- Multilevel Feedback Queue
- Multiple-Processor Scheduling
- Real-Time Scheduling
  - Hard real-time systems : 정해진 시간 안에 반드시 끝내도록 스케줄링해야 함
  - Soft real-time computing : 일반 프로세스에 비해 높은 priority를 갖도록 해야 함



#### Algorithm Evaluation

- Queueing models (이론적인 개념)
  - 확률 분포로 주어지는 arrival rate와 service rate(처리율) 등을 통해 각종 perfomance index 값을 계산
- Implementation (구현) & Measurement (성능 측정)
  - 실제 시스템에 알고리즘을 구현하여 실제 작업(workload)에 대해서 성능을 측정 비교
  - 운영체제 내부의 커널을 고쳐야 되므로 어려움
- Simulation (모의 실험)
  - 알고리즘을 모의 프로그램으로 작성 후 trace를 입력으로 하여 결과 비교 (trace : 시뮬레이션에 들어갈 input)

---



## 4. Process Synchronization

#### 데이터의 접근

- CPU --> Memory
- 컴퓨터 내부 --> 디스크
- 프로세스 --> 그 프로세스의 주소 공간



#### Race Condition(경쟁 상태)

- 여러 프로세스들이 동시에 공유 데이터를 접근하는 상황
- 데이터의 최종 연산 결과는 마지막에 그 데이터를 다룬 프로세스에 따라 달라짐
  - ex) 커널모드 수행 중 인터럽트가 발생하여 인터럽트 처리루틴이 수행
           --> 양쪽 다 커널 코드이므로 kernel address space 공유



#### OS에서 Race Condition 발생 시기

1. kernel 수행 중 인터럽트 발생 시
2. Process가 system call을 하여 kernel mode로 수행 중인데 context switch가 일어나는 경우
   - 해결책 : 커널 모드에서 수행 중일 때는 CPU를 preempt하지 않음. 커널 모드에서 사용자 모드로 돌아갈 때 preempt
3. Multiprocessor에서 shared memory 내의 kernel data
   - 해결책
     - 한번에 하나의 CPU만이 커널에 들어갈 수 있게 하는 방법
     - 커널 내부에 있는 각 공유 데이터에 접근할 때마다 그 데이터에 대한 lock / unlock을 하는 방법



#### Process Synchronization 문제

- 공유 데이터(shared data)의 동시 접근(concurrent access)은 데이터의 불일치 문제(inconsistency)를 발생시킬 수 있다
- 일관성(consistency) 유지를 위해서는 협력 프로세서(cooperating process) 간의 실행 순서(orderly execution)를 정해주는 메커니즘 필요
- Race condition을 막기 위해서는 concurrent process는 동기화(synchronize)되어야 한다



#### The Critical-Section Problem

- n개의 프로세스가 공유 데이터를 동시에 사용하기를 원하는 경우
- 각 프로세스의 code segment에는 공유 데이터를 접근하는 코드인 **critical section**이 존재
- Problem
  - 하나의 프로세스가 critical section에 있을 때 다른 모든 프로세스는 critical section에 들어갈 수 없어야 한다



#### 프로그램적 해결법의 충족 조건

- Mutual Exclusion (상호 배제)
  - 프로세스 Pi가 critical section 부분을 수행 중이면 다른 모든 프로세스들은 그들의 critical section에 들어가면 안된다
- Progress (진행)
  - 아무도 critical section에 있지 않은 상태에서 critical section에 들어가고자 하는 프로세스가 있으면 critical section에 들어가게 해주어야 한다
- Bounded waiting (유한 대기)
  - 프로세스가 critical section에 들어가려고 요청한 후부터 그 요청이 허용될 때까지 다른 프로세스들이 critical section에 들어가는 횟수에 한계가 있어야 한다



#### Synchronization 해결책

1. Peterson's Algorithm : flag로 lock을 검  --> busy-wait

2. Synchronization Hardware : Test_and_set 으로 lock 을 검(하드웨어적으로)  --> busy-wait

3. Semaphores

   - 추상화시킨 방법
   - S : 자원의 개수, P연산 : 공유 데이터를 획득하는 연산, S연산 : 가져온 데이터를 반납하는 연산

   1. busy-wait (=spin lock)
   2. Block & Wakeup (=sleep lock)



#### Which is better?

- **Busy-wait vs Block/wakeup**
- **Block/wakeup overhead vs Critical section 길이**
  - Critical section의 길이가 긴 경우 : Block/wakeup이 적당
  - Critical section의 길이가 매우 짧은 경우 : Block/wakeup의 오버헤드가 busy-wait의 오버헤드보다 커질 수 있음
  - 일반적으로는 Block/wakeup 방식이 더 좋음



#### Deadlock and Starvation

- **Deadlock**
  - 둘 이상의 프로세스가 서로 상대방에 의해 충족될 수 있는 event를 무한히 기다리는 현상
- **Starvation**
  - indefinite blocking : 프로세스가 suspend된 이유에 해당하는 세마포어 큐에서 빠져나갈 수 없는 현상



#### Semaphore의 문제점

- 코딩하기 힘들다
- 정확성(correctness)의 입증이 어렵다
- 자발적 협력(voluntary cooperation)이 필요하다
- 한번의 실수가 모든 시스템에 치명적 영향



#### Monitor

- 동시 수행중인 프로세스 사이에서 안전한 공유를 보장하기 위한 high-level synchronization construct
- Semaphore와의 차이점 : lock을 걸 필요가 없이 monitor가 알아서 공유데이터의 lock 처리를 해줌
- 모니터 내에서는 한번에 하나의 프로세스만이 활동 가능
- 프로그래머가 동기화 제약 조건을 명시적으로 코딩할 필요가 없다 (eg. lock)

---



### Deadlock

#### Deadlock Problem

- Deadlock
  - 일련의 프로세스들이 서로가 가진 자원을 기다리며 block된 상태
- Resource (자원)
  - 하드웨어, 소프트웨어 등을 포함하는 개념
  - (ex) I/O device, CPU cycle, Memory space, Semaphore 등
  - 프로세스가 자원을 사용하는 절차
    - Request, Allocate, Use, Release



#### Deadlock 발생의 4가지 필요 조건

- Mutual exclusion (상호 배제)
  - 매 순간 하나의 프로세스만이 자원을 사용할 수 있음
- No preemption (비선점)
  - 프로세스는 자원을 스스로 내어놓을 뿐 강제로 빼앗기지 않음
- Hold and wait (보유대기)
  - 자원을 가진 프로세스가 다른 자원을 기다릴 때 보유 자원을 놓지 않고 계속 가지고 있음
- Circular wait (순환대기)
  - 자원을 기다리는 프로세스간에 사이클이 형성되어야 함



#### Resource-Allocation Graph

- 그래프에 cycle이 없으면 deadlock이 아니다
- 그래프에 cycle이 있으면
  - if only one instance per resource type, then deadlock
  - if several instances per resource type, possibility of deadlock



#### Deadlock 처리 방법

- Deadlock Prevention

  - 자원 할당 시 Deadlock의 4가지 필요 조건 중 어느 하나가 만족되지 않도록 하는 것

    ==> Utilization 저하, Throughtput 감소, Starvation 문제 
    		(생기지도 않을 deadlock에 너무 많은 관심을 줘서 비효율적)

- Deadlock Avoidance

  - 자원 요청에 대한 부가적인 정보를 이용해서 deadlock의 가능성이 없는 경우에만 자원을 할당
  - 시스템 state가 원래 state로 돌아올 수 있는 경우에만 자원 할당
    - Single instance per resource types : Resource Allocation Graph algorithm 사용
    - Multiple instances per resource types : Banker's Algorithm 사용

- Deadlock Detection and Recovery

  - Deadlock 발생은 허용하되 그에 대한 detection 루틴을 두어 deadlock 발견시 recover
     ==> Starvation 문제, 비효율적 

- Deadlock Ignorance

  - Deadlock을 시스템이 책임지지 않음
    - Deadlock이 매우 드물게 발생하므로 조치를 취하는 자체가 더 큰 overhead일 수 있음
    - 만약, 시스템에 deadlock이 발생한 경우 시스템이 비정상적으로 작동하는 것을 사람이 느낀 후 직접 process를 죽이는 등의 방법으로 대처
  - UNIX를 포함한 대부분의 OS가 채택

---



### Virtual Memory

#### Demand Paging

- 실제로 필요할 때 page를 메모리에 올리는 것
  - I/O 양의 감소
  - Memory 사용량 감소
  - 빠른 응답 시간
  - 더 많은 사용자 수용
- Valid / Invalid bit의 사용
  - Invalid의 의미
    - 사용되지 않는 주소 영역인 경우
    - 페이지가 물리적 메모리에 없는 경우
  - address translation 시에 invalid bit이 set 되어 있으면
    => **"Page fault"** : 요청한 페이지가 메모리에 없는 경우(디스크에 존재) -> 자동으로 CPU가 운영체제(OS)한테 넘어감 ('page trap') -> I/O 작업(디스크에서 물리적메모리에 올리는 작업) -> page table에 valid로 표시



#### Page Fault

- invalid page를 접근하면 MMU(Memory Management Unit)가 trap을 발생시킴 (page fault trap)

- Kernel mode로 들어가서 page fault handler가 invoke됨

- 다음과 같은 순서로 page fault를 처리

  1. Invalid reference? (eg. bad address, portection violation) => abort process

  2. Get an empty page frame. (없으면 뺏어온다 : replace)

  3. 해당 페이지를 disk에서 memory로 읽어온다

     a. disk I/O가 끝나기까지 이 프로세스는 CPU를 preempt 당함 (block)

     b. Disk read가 끝나면 page tables entry 기록, valid/invalid bit = "valid"

     c. ready queue에 process를 insert -> dispatch later

  4. 이 프로세스가 CPU를 잡고 다시 running

  5. 아까 중단되었던 instruction을 재개



#### Free frame이 없는 경우

- page replacement
  - 어떤 frame을 빼앗아올지 결정해야 함
  - 곧바로 사용되지 않은 page를 쫓아내는 것이 좋음
  - 동일한 페이지가 여러 번 메모리에서 쫓겨났다가 다시 들어올 수 있음
  - OS가 하는 일(I/O 작업)!!!!
- Replacement Algorithm
  - page-fault rate을 최소화하는 것이 목표
  - 알고리즘의 평가
    - 주어진 page reference string에 대해 page fault를 얼마나 내는지 조사



#### Optimal Algorithm

- MIN (OPT) : 가장 먼 미래에 참조되는 page를 replace
- 미래의 참조를 어떻게 아는가?
  - Offline algorithm -> 현실에서는 사용 불가
- 다른 알고리즘의 성능에 대한 upper bound 제공 (흡사 카르노 사이클)
  - Belady's optimal algorithm, MIN, OPT 등으로 불림



#### FIFO (First In First Out) Algorithm

- FIFO : 먼저 들어온 것을 먼저 내쫓음
- FIFO Anomaly (Belady's Anomaly)
  - frame이 많아지면 page fault 수가 작아지는게 일반적이지만 FIFO는 많아지는 경우가 생김



#### LRU (Least Recently Used) Algorithm

- LRU : 가장 오래 전에 참조된 것을 지움



#### LFU (Least Frequently Used) Algorithm

- LFU : 참조 횟수(reference count)가 가장 적은 페이지를 지움
  - 최저 참조 횟수인 page가 여럿 있는 경우
    - LFU 알고리즘 자체에서는 여러 page 중 임의로 선정
    - 성능 향상을 위해 가장 오래 전에 참조된 page를 지우게 구현할 수도 있다
  - 장단점
    - LRU처럼 직전 참조 시점만 보는 것이 아니라 장기적인 시간 규모를 보기 때문에 page의 인기도를 좀 더 정확히 반영할 수 있음
    - 참조 시점의 최근성을 반영하지 못함
    - LRU보다 구현이 복잡함



#### 다양한 캐슁 환경

- 캐슁 기법
  - 한정된 빠른 공간(=캐쉬)에 요청된 데이터를 저장해 두었다가 후속 요청시 캐쉬로부터 직접 서비스하는 방식
    (한정된 빠른 공간 : physical memory, 느린 공간 : backing store(=swap area))
  - paging system 외에도 cache memory(Ex. TLB), buffer caching, Web caching 등 다양한 분야에서 사용
- 캐쉬 운영의 시간 제약
  - 교체 알고리즘에서 삭제할 항목을 결정하는 일에 지나치게 많은 시간이 걸리는 경우 실제 시스템에서 사용할 수 없음
  - Buffer caching이나 Web caching의 경우
    - O(1)에서 O(log n) 정도까지 허용
  - Paging system인 경우
    - page fault인 경우에만 OS가 관여함
    - 페이지가 이미 메모리에 존재하는 경우 참조시각 등의 정보를 OS가 알 수 없음
    - O(1)인 LRU의 list 조작조차 불가능
    - **Paging system에서는 LRU, LFU 같은 알고리즘 사용 불가** --> OS는 page fault인 경우에만 관여하는데 이전에 들어간 데이터들의 정보를 모르니까 OS가 swap out 할 데이터를 찾을 수 없음



#### Clock Algorithm

- LRU의 근사(approximation) 알고리즘
  (= Second chance algorithm, NUR (Not Used Recently), NRU(Not Recently Used))
- Reference bit을 사용해서 교체 대상 페이지 선정 (circular list)
- Reference bit이 0인 것을 찾을 때까지 포인터를 하나씩 앞으로 이동
- 포인터가 이동하는 중에 Reference bit 1은 모두 0으로 바꿈
- Reference bit이 0인 것을 찾으면 그 페이지를 교체
- 한 바퀴 되돌아와서도(=second chance) 0이면 그때에는 replace 당함
- 자주 사용하는 페이지라면 second chance가 올 때 1
- LRU 알고리즘과 비슷하지만 LRU는 OS가 이미 있던 page에 대해서는 알 수가 없지만, Clock 알고리즘은 reference bit이라는 하드웨어를 하나 더 줘서 page에 대한 정보를 주기 때문에 현재 가장 널리 쓰이고 있음



#### Clock Algorithm의 개선 -> LRU를 섞은 것(?)

- reference bit과 modified bit (dirty bit)을 함께 사용
- reference bit = 1 : 최근에 참조된 페이지
- modified bit = 1 : 최근에 변경된 페이지 (I/O를 동반하는 페이지)
  (modified bit = 1 인 것을 쫓아내려면 디스크에 변경사항을 다시 저장하고 쫓아내야 되므로 시간이 더 오래 걸림 -> 0인 것을 먼저 쫓아내는게 좋음)



#### Page Frame의 Allocation

- Global replacement
  - 미리 할당하는 방법을 쓰지 않겠다!! -> 다른 프로그램에 할당된 메모리도 쫓아낼 수 있음
  - Replace 시 다른 process에 할당된 frame을 빼앗아 올 수 있다
  - Process별 할당량을 조절하는 또 다른 방법임
  - FIFO, LRU, LFU 등의 알고리즘을 global replacement로 사용시에 해당
  - Working set, PFF 알고리즘 사용
- Local replacement
  - 자신에게 할당된 frame 내에서만 replacement
  - FIFO, LRU, LFU 등의 알고리즘을 process 별로 운영시



#### Thrashing

- 프로세스의 원활한 수행에 필요한 최소한의 page frame 수를 할당 받지 못한 경우
- Page fault rate가 매우 높아짐
- CPU utilization이 낮아짐
- OS는 MPD (Multiprogramming Degree)를 높여야 한다고 판단
- 또 다른 프로세스가 시스템에 추가됨 (higher MPD)
- 프로세스 당 할당된 frame의 수가 더욱 감소
- 프로세스는 page의 swap in / swap out으로 매우 바쁨
- 대부분의 시간에 CPU는 한가함 (계속 반복되는 디스크 I/O 작업으로 인해 CPU는 놀기 때문에)
- low throughput

(메모리에 올라간 프로그램이 많으면 각 프로그램마다 할당된 메모리가 적고, 그에 따라 page fault가 자주 발생하고, I/O 작업이 빈번히 일어나기 때문에 CPU 이용률이 작아짐 -> 운영체제(OS)는 CPU가 놀고 있다고 판단 -> 프로그램을 시스템에 추가)



#### Working-Set Model

- Locality of reference
  - 프로세스는 특정 시간 동안 일정 장소만을 집중적으로 참조
  - 집중적으로 참조되는 해당 page들의 집합을 locality set이라 함
- Working-set Model
  - Locality에 기반하여 프로세스가 일정 시간 동안 원활하게 수행되기 위해 한꺼번에 메모리에 올라와 있어야 하는 page들의 집합을 **Working Set**이라 정의함
  - Working Set 모델에서는 process의 working set 전체가 메모리에 올라와 있어야 수행되고 그렇지 않을 경우 모든 frame을 반납한 후 swap out (suspend)
  - Thrashing을 방지함
  - Multiprogramming degree를 결정함



#### Working-Set Algorithm

- Process들의 working set size의 합이 page frame의 수보다 큰 경우
  - 일부 process를 swap out 시켜 남은 process의 working set을 우선적으로 충족시켜 준다
    (MPD를 줄임)
- Working set을 다 할당하고도 page frame이 남는 경우
  - Swap out 되었던 프로세스에게 working set을 할당
    (MPD를 키움)



#### PFF (Page-Fault Frequency) Scheme

- page-fault rate의 상한값과 하한값을 둔다
  - Page fault rate이 상한값을 넘으면 frame을 더 할당한다
  - Page fault rate이 하한값 이하이면 할당 frame 수를 줄인다
- 빈 frame이 없으면 일부 프로세스를 swap out



#### Page size의 결정

- 일반적으로 page size = 4KB
- Page size를 감소시키면
  - 페이지 수 증가
  - 페이지 테이블 크기 증가
  - Internal fragmentation 감소
    (잘게 쪼개니까 내부 조각 감소(?))
  - Disk transfer의 효율성 감소
    - Seek/rotation vs. transfer
      : 디스크 헤드가 이동하는데 걸리는 시간이 오래 걸리므로 찾은 위치에서 많은 양의 정보를 가져오는게 시간적으로 유리할 수 있음
  - 필요한 정보만 메모리에 올라와 메모리 이용이 효율적
    (페이지 크기가 크면 작은 양의 정보만 필요해도 대량의 정보를 메모리에 올려야 되므로!)
    - Locality의 활용 측면에서는 좋지 않음
      (한번에 많은 양의 정보를 올리면 그 함수에서 참조할 함수도 같이 올라오므로 다시 page fault가 나지 않고 바로 참조가 가능하므로)
- 현재 트렌드!! --> Larger page size

---



### File System

#### File and File System

- File
  - "A named collection of related information"
  - 일반적으로 비휘발성의 보조기억장치에 저장
  - 운영체제는 다양한 저장 장치를 file이라는 동일한 논리적 단위로 볼 수 있게 해줌
  - Operation
    - create, read, write, reposition (lseek), delete, open, close 등
- 



#### 









