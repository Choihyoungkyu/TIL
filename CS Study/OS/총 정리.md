# 총 정리



## 1. System Structure & Program Execution



#### 운영체제(Operating System, OS)

- 컴퓨터 하드웨어 바로 위에 설치되어 사용자 및 다른 모든 소프트웨어와 하드웨어를 연결하는 소프트웨어 계층
  - 협의의 운영체제(커널) : 운영체제의 핵심 부분으로 메모리에 상주하는 부분
  - 광의의 운영체제 : 커널 뿐 아니라 각종 주변 시스템 유틸리티를 포함한 개념



#### 운영체제의 목적

- 컴퓨터 시스템의 **자원을 효율적으로 관리**
- 컴퓨터 시스템을 편리하게 사용할 수 있는 **환경 제공**
- 즉, 사용자의 요청에 대해 빠르고 정확하게 시스템 자원을 제공하고 많은 양의 데이터를 처리해주기 위해 필요



#### 운영체제의 역할

- 프로세스 관리
  - 프로세스의 생성, 제거, 중지, 재시작, 동기화
  - 프로세스간 통신
  - 교착상태 방지 기법 등을 제공
- 기억장치 관리
  - 주기억장치 이용 프로세스 파악
  - 주기억장치에 프로세스를 적제 및 회수
- 입출력장치 관리
  - 입출력장치의 상태 파악
  - 입출력장치 스케줄링
- 정보 관리
  - 파일 생성 및 제거
  - 파일 & 디렉토리 관리



#### 컴퓨터 시스템 구조

- 컴퓨터 : CPU + Memory
- I/O device : 하드디스크(보조기억장치), 모니터, 키보드, 프린터 등등



#### Mode bit

- 0일 때(OS가 CPU를 가지고 있을 때) : 다 가능 (**interrupt가 들어오면 CPU가 OS에게 넘어감**)
- 1일 때(사용자 프로그램이 CPU를 가지고 있을 때) : 한정된 instruction만 실행 가능

CPU는 일반적으로 사용자 프로그램을 순차적으로 수행(mode bit == 1)
만약, 사용자 프로그램에서 I/O device에 접근을 해야 하는 경우 ---> system call
==> 의도적으로 interrupt line을 설정해 CPU가 멈추게 하고, OS한테 CPU를 넘겨줌(mode bit = 0)



#### 동기식 입출력과 비동기식 입출력

- I/O는 커널을 통해서만 가능
- 동기식 입출력 (synchronous I/O)
  - I/O 요청 후 입출력 작업이 완료된 후에야 제어가 사용자 프로그램에 넘어감
- 비동기식 입출력 (asynchronous I/O)
  - I/O가 시작된 후 입출력 작업이 끝나기를 기다리지 않고 제어가 사용자 프로그램에 즉시 넘어감



#### DMA (Direct Memory Access)

- 빠른 입출력 장치를 메모리에 가까운 속도로 처리하기 위해 사용
- CPU의 중재 없이 device controller가 device의 buffer storage의 내용을 메모리에 block 단위로 직접 전송
- 바이트 단위가 아니라 block 단위로 인터럽트를 발생시킴



#### 커널 주소 공간의 내용

- code
  - 시스템콜, 인터럽트 처리 코드
  - 자원 관리를 위한 코드
  - 편리한 서비스 제공을 위한 코드
- data
  - Table(Data Structure) - Object(Hardware or Software)
- stack
  - Process A의 커널 스택

---



## 2. Process



#### 프로세스의 상태 (Process State)

- **Running**
  - CPU를 잡고 instruction을 수행중인 상태
- **Ready**
  - CPU를 기다리는 상태(메모리 등 다른 조건을 모두 만족하고)
- **Blocked (wait, sleep)**
  - CPU를 주어도 당장 instruction을 수행할 수 없는 상태
  - Process 자신이 요청한 event(예 : I/O)가 즉시 만족되지 않아 이를 기다리는 상태
  - ex) 디스크에서 file을 읽어와야 하는 경우
- **Suspended (stopped)** 
  - 외부적인 이유로 프로세스의 수행이 정지된 상태
  - 프로세스는 통째로 디스크에 swap out 된다
  - ex)
    - 사용자가 프로그램을 일시 정지 시킨 경우 (break key)
    - 시스템이 여러 이유로 프로세스를 잠시 중단 시킨 경우 (메모리에 너무 많은 프로세스가 올라와 있을 때)

- **New**
  - 프로세스가 생성중인 상태
- **Terminated**
  - 수행(execution)이 끝난 상태 --> 정리할게 남아 있는 상태
  - Blocked 와 차이점 
    - Blocked는 자신이 요청한 event가 만족되면 Ready
    - Suspended는 외부에서 resume 해주어야 Active



#### PCB (Process Control Block)

- 운영체제가 각 프로세스를 관리하기 위해 프로세스당 유지하는 정보
  1. OS가 관리상 사용하는 정보
     - Process state, Process ID
     - scheduling information, priority
  2. CPU 수행 관련 하드웨어 값
     - Program counter, registers
  3. 메모리 관련
     - code, data, stack의 위치 정보
  4. 파일 관련
     - Open file descriptors



#### 문맥 교환 (Context Switch)

- CPU를 한 프로세스에서 다른 프로세스로 넘겨주는 과정
- CPU가 다른 프로세스에게 넘어갈 때 운영체제는 다음을 수행
  - CPU를 내어주는 프로세스의 상태를 그 프로세스의 PCB에 저장
  - CPU를 새롭게 얻는 프로세스의 상태를 PCB에서 읽어옴
- System call이나 Interrupt 발생 시 반드시 context switch가 일어나는 것은 아님



#### 프로세스 스케줄링 큐

- Job queue
  - 현재 시스템 내에 있는 모든 프로세스의 집합
- Ready queue (CPU를 기다리는 줄)
  - 현재 메모리 내에 있으면서 CPU를 잡아서 실행되기를 기다리는 프로세스의 집합
- Device queues
  - I/O device의 처리를 기다리는 프로세스의 집합



#### 스케줄러 (Scheduler)

- Long-term scheduler (장기 스케줄러 or job scheduler)
  - 시작 프로세스 중 어떤 것들을 **ready queue**로 보낼지 결정
  - 프로세스에 **memory** 및 각종 자원을 주는 문제
  - degree of Multiprogramming을 제어
  - time sharing system에는 보통 장기 스케줄러가 없음 (무조건 ready)
- Short-term scheduler (단기 스케줄러 or CPU scheduler)
  - 어떤 프로세스를 다음번에 running 시킬지 결정
  - 프로세스에 **CPU**를 주는 문제
  - 충분히 빨라야 함 (millisecond 단위)
- Medium-Term scheduler (중기 스케줄러 or Swapper)
  - 여유 공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫓아냄
  - 프로세스에게서 **memory**를 뺏는 문제 --> Suspended 상태가 됨
  - degree of Multiprogramming을 제어



#### Thread

- 다중 스레드로 구성된 태스크 구조에서는 하나의 서버 스레드가 blocked (waiting) 상태인 동안에도 동일한 태스크 내의 다른 스레드가 실행(running)되어 빠른 처리를 할 수 있다.
- 동일한 일을 수행하는 다중 스레드가 협력하여 높은 처리율(throughput)과 성능 향상을 얻을 수 있다
- 스레드를 사용하면 병렬성을 높일 수 있다  (CPU가 여러개 달린 컴퓨터에서만 가능)



#### Thread 사용의 장점

- 반응성 (Responsiveness)
  - eg) multi-threaded Web
    - if one thread is blocked (eg network) another thread continues (eg display)
- 자원 공유 (Resource Sharing)
  - n threads can share binary code, data, resource of the process
- 경제성 (Economy)
  - creating & CPU switching thread (rather than a process)
    (process를 생성하고 process를 스위칭하는 것보다 훨씬 빠름)
- 유용성 (Utilization of MP(Multi Processor : CPU가 여러개) Architectures)
  - each thread may be running in parallel on a different processor

---



## 3. Process Management & CPU Scheduling



#### 프로세스 생성

- 부모 프로세스가 자식 프로세스를 생성
  - 자신의 메모리(코드, 데이터, 스택), CPU의 문맥(PCB)까지 복사
- 일반적으로 부모가 프로세스를 생성하고 나면 서로 경쟁관계가 되어 자원을 공유하지 않음



#### 프로세스의 종료

- 자발적 종료
  - 마지막 statement 수행 후 exit() 시스템 콜을 통해
  - 프로그램에 명시적으로 적어주지 않아도 main 함수가 리턴되는 위치에 컴파일러가 넣어줌
- 비자발적 종료
  - 부모 프로세스가 자식 프로세스를 강제 종료시킴
    - 자식 프로세스가 한계치를 넘어서는 자원 요청 -> 욕심부리면 죽임
    - 자식에게 할당된 태스크가 더 이상 필요하지 않음 -> 무쓸모면 죽임
  - 키보드로 kill, break 등을 친 경우
  - 부모가 종료하는 경우
    - 부모 프로세스가 종료하기 전에 자식들이 먼저 종료됨



#### CPU Scheduler & Dispatcher -> 각각 OS 내의 코드

- CPU Scheduler
  - OS 안에서 스케줄링을 해주는 코드
  - Ready 상태의 프로세스 중에서 이번 CPU를 줄 프로세스를 선택 (단기 스케줄러(?))
- Dispatcher
  - CPU의 제어권을 CPU scheduler에 의해 선택된 프로세스에게 제공
  - 이 과정을 Context Switch (문맥 교환)라고 한다
- CPU 스케줄링이 필요한 경우
  1. Running -> Blocked (eg I/O 요청하는 시스템 콜)
  2. Running -> Ready (eg 할당시간만료로 timer interrupt)
  3. Blocked -> Ready (eg I/O 완료 후 인터럽트)
  4. Terminate (eg 프로세스 종료)
- Nonpreemptive : 강제로 빼앗지 않고 자진 반납 (1, 4번)
- Preemptive : 강제로 빼앗음 (나머지) --> 현재 많이 씀



#### Scheduling Criteria : Performance Index (= 성능 척도)

- **시스템 입장**에서의 성능 척도

  - **CPU utilization(이용률)** ---> 주방장의 순수 일한 시간
    - keep the CPU as busy as possible
  - **Throughput(처리량)** ---> 먹고 나간 손님의 총 수
    - `#` of processes that complete their execution per time unit

- **프로세스 입장**에서의 성능 척도

  - **Turnaround time(소요시간, 반환시간)** ---> 손님이 들어와서 나갈때까지의 시간

    - amount of time to execute a particular process

  - **Waiting time(대기시간)** ---> 손님이 코스요리를 먹을 경우 음식을 기다리는 총 시간

    - amount of time a process has been waiting in the ready queue
    - 선점형(preemptive)일 경우 CPU를 뺏겼다가 다시 잡는 대기시간까지 합한게 대기시간

  - **Response time(응답시간)** ---> 손님이 코스요리를 먹을 경우 첫 음식이 나오기까지의 시간

    - amount of time it takes from when a request was submitted until the first response is producted. not output (for time-sharing environment)

    - 처음 CPU를 받을 때까지 걸린 시간



#### Scheduling Algorithms

- FCFS (First-Come First-Served)
- SJF ( Shortest-Job-First)
  - 일종의 priority scheduling
  - 각 프로세스의 다음번 CPU burst time을 가지고 스케줄링에 활용
  - Preemptive일 경우
    - 현재 수행중인 프로세스의 남은 burst time보다 더 짧은 CPU burst time을 가지는 새로운 프로세스가 도착하면 CPU를 뺏김
    - 이 방법을 Shortest-Remaining-Time-First (SRTF)라고 부름
  - 문제점
    - starvation(기아 현상)
    - 다음번 CPU burst를 알 수 없다 -> 과거의 CPU burst time을 이용해서 추정(exponential averaging)

- Priority Scheduling
  - highest priority를 가진 프로세스에게 CPU를 할당
  - 문제점 : Starvation
  - 해결책 : Aging - as time progresses increase the priority of the process
- Round Robin (RR)
  - 각 프로세스는 동일한 크기의 할당시간(time quantum)을 가지고, 할당 시간이 지나면 프로세스는 선점(preempted) 당하고 ready queue의 젤 뒤에 다시 줄을 섬
  - 할당시간(q)이 크면 --> FCFS
  - 할당시간(q)가 작으면 --> context switch 오버헤드가 커진다
  - 일반적으로 SJF보다 average turnaround time(소요 시간)이 길지만 response time(응답 시간)은 짧다
- Multilevel Queue
  - Ready queue를 여러 개로 분할
    - foreground (interactive) - **RR**
    - background (batch - no human interaction) - **FCFS**
  - 큐에 대한 스케줄링이 필요
    - **Fixed priority scheduling**
      - foreground가 다 차면 background로
      - Possibility of starvation
    - **Time slice**
      - 각 큐에 CPU time을 적절한 비율로 할당
- Multilevel Feedback Queue
- Multiple-Processor Scheduling
- Real-Time Scheduling
  - Hard real-time systems : 정해진 시간 안에 반드시 끝내도록 스케줄링해야 함
  - Soft real-time computing : 일반 프로세스에 비해 높은 priority를 갖도록 해야 함



#### Algorithm Evaluation

- Queueing models (이론적인 개념)
  - 확률 분포로 주어지는 arrival rate와 service rate(처리율) 등을 통해 각종 perfomance index 값을 계산
- Implementation (구현) & Measurement (성능 측정)
  - 실제 시스템에 알고리즘을 구현하여 실제 작업(workload)에 대해서 성능을 측정 비교
  - 운영체제 내부의 커널을 고쳐야 되므로 어려움
- Simulation (모의 실험)
  - 알고리즘을 모의 프로그램으로 작성 후 trace를 입력으로 하여 결과 비교 (trace : 시뮬레이션에 들어갈 input)

---



## 4. Process Synchronization

#### 데이터의 접근

- CPU --> Memory
- 컴퓨터 내부 --> 디스크
- 프로세스 --> 그 프로세스의 주소 공간



#### Race Condition(경쟁 상태)

- 여러 프로세스들이 동시에 공유 데이터를 접근하는 상황
- 데이터의 최종 연산 결과는 마지막에 그 데이터를 다룬 프로세스에 따라 달라짐
  - ex) 커널모드 수행 중 인터럽트가 발생하여 인터럽트 처리루틴이 수행
           --> 양쪽 다 커널 코드이므로 kernel address space 공유



#### OS에서 Race Condition 발생 시기

1. kernel 수행 중 인터럽트 발생 시
2. Process가 system call을 하여 kernel mode로 수행 중인데 context switch가 일어나는 경우
   - 해결책 : 커널 모드에서 수행 중일 때는 CPU를 preempt하지 않음. 커널 모드에서 사용자 모드로 돌아갈 때 preempt
3. Multiprocessor에서 shared memory 내의 kernel data
   - 해결책
     - 한번에 하나의 CPU만이 커널에 들어갈 수 있게 하는 방법
     - 커널 내부에 있는 각 공유 데이터에 접근할 때마다 그 데이터에 대한 lock / unlock을 하는 방법



#### Process Synchronization 문제

- 공유 데이터(shared data)의 동시 접근(concurrent access)은 데이터의 불일치 문제(inconsistency)를 발생시킬 수 있다
- 일관성(consistency) 유지를 위해서는 협력 프로세서(cooperating process) 간의 실행 순서(orderly execution)를 정해주는 메커니즘 필요
- Race condition을 막기 위해서는 concurrent process는 동기화(synchronize)되어야 한다



#### The Critical-Section Problem

- n개의 프로세스가 공유 데이터를 동시에 사용하기를 원하는 경우
- 각 프로세스의 code segment에는 공유 데이터를 접근하는 코드인 **critical section**이 존재
- Problem
  - 하나의 프로세스가 critical section에 있을 때 다른 모든 프로세스는 critical section에 들어갈 수 없어야 한다



#### 프로그램적 해결법의 충족 조건

- Mutual Exclusion (상호 배제)
  - 프로세스 Pi가 critical section 부분을 수행 중이면 다른 모든 프로세스들은 그들의 critical section에 들어가면 안된다
- Progress (진행)
  - 아무도 critical section에 있지 않은 상태에서 critical section에 들어가고자 하는 프로세스가 있으면 critical section에 들어가게 해주어야 한다
- Bounded waiting (유한 대기)
  - 프로세스가 critical section에 들어가려고 요청한 후부터 그 요청이 허용될 때까지 다른 프로세스들이 critical section에 들어가는 횟수에 한계가 있어야 한다



#### Synchronization 해결책

1. Peterson's Algorithm : flag로 lock을 검  --> busy-wait

2. Synchronization Hardware : Test_and_set 으로 lock 을 검(하드웨어적으로)  --> busy-wait

3. Semaphores

   - 추상화시킨 방법
   - S : 자원의 개수, P연산 : 공유 데이터를 획득하는 연산, S연산 : 가져온 데이터를 반납하는 연산

   1. busy-wait (=spin lock)
   2. Block & Wakeup (=sleep lock)



#### Which is better?

- **Busy-wait vs Block/wakeup**
- **Block/wakeup overhead vs Critical section 길이**
  - Critical section의 길이가 긴 경우 : Block/wakeup이 적당
  - Critical section의 길이가 매우 짧은 경우 : Block/wakeup의 오버헤드가 busy-wait의 오버헤드보다 커질 수 있음
  - 일반적으로는 Block/wakeup 방식이 더 좋음



#### Deadlock and Starvation

- **Deadlock**
  - 둘 이상의 프로세스가 서로 상대방에 의해 충족될 수 있는 event를 무한히 기다리는 현상
- **Starvation**
  - indefinite blocking : 프로세스가 suspend된 이유에 해당하는 세마포어 큐에서 빠져나갈 수 없는 현상



#### Semaphore의 문제점

- 코딩하기 힘들다
- 정확성(correctness)의 입증이 어렵다
- 자발적 협력(voluntary cooperation)이 필요하다
- 한번의 실수가 모든 시스템에 치명적 영향



#### Monitor

- 동시 수행중인 프로세스 사이에서 안전한 공유를 보장하기 위한 high-level synchronization construct
- Semaphore와의 차이점 : lock을 걸 필요가 없이 monitor가 알아서 공유데이터의 lock 처리를 해줌
- 모니터 내에서는 한번에 하나의 프로세스만이 활동 가능
- 프로그래머가 동기화 제약 조건을 명시적으로 코딩할 필요가 없다 (eg. lock)

---



### 5. Deadlock

#### Deadlock Problem

- Deadlock
  - 일련의 프로세스들이 서로가 가진 자원을 기다리며 block된 상태
- Resource (자원)
  - 하드웨어, 소프트웨어 등을 포함하는 개념
  - (ex) I/O device, CPU cycle, Memory space, Semaphore 등
  - 프로세스가 자원을 사용하는 절차
    - Request, Allocate, Use, Release



#### Deadlock 발생의 4가지 필요 조건

- Mutual exclusion (상호 배제)
  - 매 순간 하나의 프로세스만이 자원을 사용할 수 있음
- No preemption (비선점)
  - 프로세스는 자원을 스스로 내어놓을 뿐 강제로 빼앗기지 않음
- Hold and wait (보유대기)
  - 자원을 가진 프로세스가 다른 자원을 기다릴 때 보유 자원을 놓지 않고 계속 가지고 있음
- Circular wait (순환대기)
  - 자원을 기다리는 프로세스간에 사이클이 형성되어야 함



#### Resource-Allocation Graph

- 그래프에 cycle이 없으면 deadlock이 아니다
- 그래프에 cycle이 있으면
  - if only one instance per resource type, then deadlock
  - if several instances per resource type, possibility of deadlock



#### Deadlock 처리 방법

- Deadlock Prevention

  - 자원 할당 시 Deadlock의 4가지 필요 조건 중 어느 하나가 만족되지 않도록 하는 것

    ==> Utilization 저하, Throughtput 감소, Starvation 문제 
    		(생기지도 않을 deadlock에 너무 많은 관심을 줘서 비효율적)

- Deadlock Avoidance

  - 자원 요청에 대한 부가적인 정보를 이용해서 deadlock의 가능성이 없는 경우에만 자원을 할당
  - 시스템 state가 원래 state로 돌아올 수 있는 경우에만 자원 할당
    - Single instance per resource types : Resource Allocation Graph algorithm 사용
    - Multiple instances per resource types : Banker's Algorithm 사용

- Deadlock Detection and Recovery

  - Deadlock 발생은 허용하되 그에 대한 detection 루틴을 두어 deadlock 발견시 recover
     ==> Starvation 문제, 비효율적 

- Deadlock Ignorance

  - Deadlock을 시스템이 책임지지 않음
    - Deadlock이 매우 드물게 발생하므로 조치를 취하는 자체가 더 큰 overhead일 수 있음
    - 만약, 시스템에 deadlock이 발생한 경우 시스템이 비정상적으로 작동하는 것을 사람이 느낀 후 직접 process를 죽이는 등의 방법으로 대처
  - UNIX를 포함한 대부분의 OS가 채택

---



### 6. Virtual Memory

#### Demand Paging

- 실제로 필요할 때 page를 메모리에 올리는 것
  - I/O 양의 감소
  - Memory 사용량 감소
  - 빠른 응답 시간
  - 더 많은 사용자 수용
- Valid / Invalid bit의 사용
  - Invalid의 의미
    - 사용되지 않는 주소 영역인 경우
    - 페이지가 물리적 메모리에 없는 경우
  - address translation 시에 invalid bit이 set 되어 있으면
    => **"Page fault"** : 요청한 페이지가 메모리에 없는 경우(디스크에 존재) -> 자동으로 CPU가 운영체제(OS)한테 넘어감 ('page trap') -> I/O 작업(디스크에서 물리적메모리에 올리는 작업) -> page table에 valid로 표시



#### Page Fault

- invalid page를 접근하면 MMU(Memory Management Unit)가 trap을 발생시킴 (page fault trap)

- Kernel mode로 들어가서 page fault handler가 invoke됨

- 다음과 같은 순서로 page fault를 처리

  1. Invalid reference? (eg. bad address, portection violation) => abort process

  2. Get an empty page frame. (없으면 뺏어온다 : replace)

  3. 해당 페이지를 disk에서 memory로 읽어온다

     a. disk I/O가 끝나기까지 이 프로세스는 CPU를 preempt 당함 (block)

     b. Disk read가 끝나면 page tables entry 기록, valid/invalid bit = "valid"

     c. ready queue에 process를 insert -> dispatch later

  4. 이 프로세스가 CPU를 잡고 다시 running

  5. 아까 중단되었던 instruction을 재개



#### Free frame이 없는 경우

- page replacement
  - 어떤 frame을 빼앗아올지 결정해야 함
  - 곧바로 사용되지 않은 page를 쫓아내는 것이 좋음
  - 동일한 페이지가 여러 번 메모리에서 쫓겨났다가 다시 들어올 수 있음
  - OS가 하는 일(I/O 작업)!!!!
- Replacement Algorithm
  - page-fault rate을 최소화하는 것이 목표
  - 알고리즘의 평가
    - 주어진 page reference string에 대해 page fault를 얼마나 내는지 조사



#### Optimal Algorithm

- MIN (OPT) : 가장 먼 미래에 참조되는 page를 replace
- 미래의 참조를 어떻게 아는가?
  - Offline algorithm -> 현실에서는 사용 불가
- 다른 알고리즘의 성능에 대한 upper bound 제공 (흡사 카르노 사이클)
  - Belady's optimal algorithm, MIN, OPT 등으로 불림



#### FIFO (First In First Out) Algorithm

- FIFO : 먼저 들어온 것을 먼저 내쫓음
- FIFO Anomaly (Belady's Anomaly)
  - frame이 많아지면 page fault 수가 작아지는게 일반적이지만 FIFO는 많아지는 경우가 생김



#### LRU (Least Recently Used) Algorithm

- LRU : 가장 오래 전에 참조된 것을 지움



#### LFU (Least Frequently Used) Algorithm

- LFU : 참조 횟수(reference count)가 가장 적은 페이지를 지움
  - 최저 참조 횟수인 page가 여럿 있는 경우
    - LFU 알고리즘 자체에서는 여러 page 중 임의로 선정
    - 성능 향상을 위해 가장 오래 전에 참조된 page를 지우게 구현할 수도 있다
  - 장단점
    - LRU처럼 직전 참조 시점만 보는 것이 아니라 장기적인 시간 규모를 보기 때문에 page의 인기도를 좀 더 정확히 반영할 수 있음
    - 참조 시점의 최근성을 반영하지 못함
    - LRU보다 구현이 복잡함



#### 다양한 캐슁 환경

- 캐슁 기법
  - 한정된 빠른 공간(=캐쉬)에 요청된 데이터를 저장해 두었다가 후속 요청시 캐쉬로부터 직접 서비스하는 방식
    (한정된 빠른 공간 : physical memory, 느린 공간 : backing store(=swap area))
  - paging system 외에도 cache memory(Ex. TLB), buffer caching, Web caching 등 다양한 분야에서 사용
- 캐쉬 운영의 시간 제약
  - 교체 알고리즘에서 삭제할 항목을 결정하는 일에 지나치게 많은 시간이 걸리는 경우 실제 시스템에서 사용할 수 없음
  - Buffer caching이나 Web caching의 경우
    - O(1)에서 O(log n) 정도까지 허용
  - Paging system인 경우
    - page fault인 경우에만 OS가 관여함
    - 페이지가 이미 메모리에 존재하는 경우 참조시각 등의 정보를 OS가 알 수 없음
    - O(1)인 LRU의 list 조작조차 불가능
    - **Paging system에서는 LRU, LFU 같은 알고리즘 사용 불가** --> OS는 page fault인 경우에만 관여하는데 이전에 들어간 데이터들의 정보를 모르니까 OS가 swap out 할 데이터를 찾을 수 없음



#### Clock Algorithm

- LRU의 근사(approximation) 알고리즘
  (= Second chance algorithm, NUR (Not Used Recently), NRU(Not Recently Used))
- Reference bit을 사용해서 교체 대상 페이지 선정 (circular list)
- Reference bit이 0인 것을 찾을 때까지 포인터를 하나씩 앞으로 이동
- 포인터가 이동하는 중에 Reference bit 1은 모두 0으로 바꿈
- Reference bit이 0인 것을 찾으면 그 페이지를 교체
- 한 바퀴 되돌아와서도(=second chance) 0이면 그때에는 replace 당함
- 자주 사용하는 페이지라면 second chance가 올 때 1
- LRU 알고리즘과 비슷하지만 LRU는 OS가 이미 있던 page에 대해서는 알 수가 없지만, Clock 알고리즘은 reference bit이라는 하드웨어를 하나 더 줘서 page에 대한 정보를 주기 때문에 현재 가장 널리 쓰이고 있음



#### Clock Algorithm의 개선 -> LRU를 섞은 것(?)

- reference bit과 modified bit (dirty bit)을 함께 사용
- reference bit = 1 : 최근에 참조된 페이지
- modified bit = 1 : 최근에 변경된 페이지 (I/O를 동반하는 페이지)
  (modified bit = 1 인 것을 쫓아내려면 디스크에 변경사항을 다시 저장하고 쫓아내야 되므로 시간이 더 오래 걸림 -> 0인 것을 먼저 쫓아내는게 좋음)



#### Page Frame의 Allocation

- Global replacement
  - 미리 할당하는 방법을 쓰지 않겠다!! -> 다른 프로그램에 할당된 메모리도 쫓아낼 수 있음
  - Replace 시 다른 process에 할당된 frame을 빼앗아 올 수 있다
  - Process별 할당량을 조절하는 또 다른 방법임
  - FIFO, LRU, LFU 등의 알고리즘을 global replacement로 사용시에 해당
  - Working set, PFF 알고리즘 사용
- Local replacement
  - 자신에게 할당된 frame 내에서만 replacement
  - FIFO, LRU, LFU 등의 알고리즘을 process 별로 운영시



#### Thrashing

- 프로세스의 원활한 수행에 필요한 최소한의 page frame 수를 할당 받지 못한 경우
- Page fault rate가 매우 높아짐
- CPU utilization이 낮아짐
- OS는 MPD (Multiprogramming Degree)를 높여야 한다고 판단
- 또 다른 프로세스가 시스템에 추가됨 (higher MPD)
- 프로세스 당 할당된 frame의 수가 더욱 감소
- 프로세스는 page의 swap in / swap out으로 매우 바쁨
- 대부분의 시간에 CPU는 한가함 (계속 반복되는 디스크 I/O 작업으로 인해 CPU는 놀기 때문에)
- low throughput

(메모리에 올라간 프로그램이 많으면 각 프로그램마다 할당된 메모리가 적고, 그에 따라 page fault가 자주 발생하고, I/O 작업이 빈번히 일어나기 때문에 CPU 이용률이 작아짐 -> 운영체제(OS)는 CPU가 놀고 있다고 판단 -> 프로그램을 시스템에 추가)



#### Working-Set Model

- Locality of reference
  - 프로세스는 특정 시간 동안 일정 장소만을 집중적으로 참조
  - 집중적으로 참조되는 해당 page들의 집합을 locality set이라 함
- Working-set Model
  - Locality에 기반하여 프로세스가 일정 시간 동안 원활하게 수행되기 위해 한꺼번에 메모리에 올라와 있어야 하는 page들의 집합을 **Working Set**이라 정의함
  - Working Set 모델에서는 process의 working set 전체가 메모리에 올라와 있어야 수행되고 그렇지 않을 경우 모든 frame을 반납한 후 swap out (suspend)
  - Thrashing을 방지함
  - Multiprogramming degree를 결정함



#### Working-Set Algorithm

- Process들의 working set size의 합이 page frame의 수보다 큰 경우
  - 일부 process를 swap out 시켜 남은 process의 working set을 우선적으로 충족시켜 준다
    (MPD를 줄임)
- Working set을 다 할당하고도 page frame이 남는 경우
  - Swap out 되었던 프로세스에게 working set을 할당
    (MPD를 키움)



#### PFF (Page-Fault Frequency) Scheme

- page-fault rate의 상한값과 하한값을 둔다
  - Page fault rate이 상한값을 넘으면 frame을 더 할당한다
  - Page fault rate이 하한값 이하이면 할당 frame 수를 줄인다
- 빈 frame이 없으면 일부 프로세스를 swap out



#### Page size의 결정

- 일반적으로 page size = 4KB
- Page size를 감소시키면
  - 페이지 수 증가
  - 페이지 테이블 크기 증가
  - Internal fragmentation 감소
    (잘게 쪼개니까 내부 조각 감소(?))
  - Disk transfer의 효율성 감소
    - Seek/rotation vs. transfer
      : 디스크 헤드가 이동하는데 걸리는 시간이 오래 걸리므로 찾은 위치에서 많은 양의 정보를 가져오는게 시간적으로 유리할 수 있음
  - 필요한 정보만 메모리에 올라와 메모리 이용이 효율적
    (페이지 크기가 크면 작은 양의 정보만 필요해도 대량의 정보를 메모리에 올려야 되므로!)
    - Locality의 활용 측면에서는 좋지 않음
      (한번에 많은 양의 정보를 올리면 그 함수에서 참조할 함수도 같이 올라오므로 다시 page fault가 나지 않고 바로 참조가 가능하므로)
- 현재 트렌드!! --> Larger page size

---



### 7. File System

#### File and File System

- File
  - "A named collection of related information"
  - 일반적으로 비휘발성의 보조기억장치에 저장
  - 운영체제는 다양한 저장 장치를 file이라는 동일한 논리적 단위로 볼 수 있게 해줌
  - Operation
    - create, read, write, reposition (lseek), delete, open, close 등
- File attibute (혹은 파일의 metadata)
  - 파일 자체의 내용이 아니라 파일을 관리하기 위한 각종 정보들
    - 파일 이름, 유형, 저장된 위치, 파일 사이즈
    - 접근 권한 (읽기/쓰기/실행), 시간 (생성/변경/사용), 소유자 등

- File system
  - 운영체제에서 파일을 관리하는 부분
  - 파일 및 파일의 메타데이터, 디렉토리 정보 등을 관리
  - 파일의 저장 방법 결정
  - 파일 보호 등




#### Directory and Logical Disk

- Directory
  - 파일의 메타데이터 중 일부를 보관하고 있는 일종의 특별한 파일
  - 그 디렉토리에 속한 파일 이름 및 파일 attribute들
  - operation
    - search for a file, create a file, delete a file
    - list a directory, rename a file, traverse the file system
- Partition (=Logical Disk)
  - 하나의 (물리적) 디스크 안에 여러 파티션을 두는게 일반적
  - 여러 개의 물리적인 디스크를 하나의 파티션으로 구성하기도 함
  - (물리적) 디스크를 파티션으로 구성한 뒤 각각의 파티션에 file system을 깔거나 swapping 등 다른 용도로 사용할 수 있음



#### Open()

- 디스크의 메타데이터를 메모리에 올려놓는 작업
- Directory path의 search에 너무 많은 시간 소요
  - Open을 read / write와 별도로 두는 이유
  - 한번 open한 파일은 read / write 시 directory search 불필요
- Open file table
  - 현재 open 된 파일들의 메타데이터 보관소 (in memory)
  - 디스크의 메타데이터보다 몇 가지 정보가 추가
    - Open한 프로세스의 수
    - File offset : 파일 어느 위치에 접근 중인지 표시 (별도 테이블 필요)
- File descriptor (file handle, file control block)
  - Open file table에 대한 위치 정보 (프로세스 별)
- File System에서의 동작들은 시스템콜이므로 운영체제한테 CPU가 넘어간다!!!
- Open을 하든 read를 하든 파일이 buffer cash에 있는지 확인하므로 LRU or LFU 알고리즘 사용 가능 (운영체제가 다 알고 있기 때문에)



#### File Protection

- 각 파일에 대해 누구에게 어떤 유형의 접근 (read/write/execution)을 허락할 것인가?

- Access Control 방법

  - Access control Matrix
    - Access control list : 파일별로 누구에게 어떤 접근 권한이 있는지 표시 (DB에서 Column)
    - Capability : 사용자별로 자신이 접근 권한을 가진 파일 및 해당 권한 표시 (DB에서 Record)

  - Grouping
    - 전체 user를 owner, group, public의 세 그룹으로 구분
    - 각 파일에 대해 세 그룹의 접근 권한(rwx)을 3비트씩으로 표시
    - (예) UNIX
      - owner(rwx) - group(r--) - other(r--)
  - Password
    - 파일마다 password를 두는 방법 (디렉토리 파일에 두는 방법도 가능)
    - 모든 접근 권한에 대해 하나의 password: all-or-nothing
    - 접근 권한별 password: 암기 문제, 관리 문제



#### Access Methods

- 시스템이 제공하는 파일 정보의 접근 방식
  - 순차 접근 (sequential access)
    - 카세트 테이프를 사용하는 방식처럼 접근
    - 읽거나 쓰면 offset은 자동적으로 증가
  - 직접 접근 (direct access, random access)
    - LP 레코드 판과 같이 접근하도록 함
    - 파일을 구성하는 레코드를 임의의 순서로 접근할 수 있음

---



### 8. File System Implementation

#### Allocation of File Data in Disk (파일 저장 시스템)

#### Contiguous Allocation (연속 할당)

- 장점
  - Fast I/O
    - 한번의 seek/rotation으로 많은 바이트 transfer
    - Realtime file 용으로, 또는 이미 run 중이던 process의 swapping 용
  - Direct access (=random access) 가능
- 단점
  - external fragmentation
  - File grow가 어려움
    - file 생성시 얼마나 큰 hole을 배당할 것인가?
    - grow 가능 vs 낭비 (internal fragementation(내부 조각))



#### Linked Allocation

- 장점
  - 외부 조각 발생 X
- 단점
  - 직접 접근 불가 (주소를 모르기 때문에)
  - Reliability 문제
    - 한 sector가 고장나 pointer가 유실되면 많은 부분을 잃음
  - Pointer를 위한 공간이 block의 일부가 되어 공간 효율성을 떨어뜨림
    - 512 bytes/sector, 4 bytes/pointer
- 변형
  - File-Allocation Table (FAT) 파일 시스템
    - 포인터를 별도의 위치에 보관하여 reliability와 공간효율성 문제 해결



#### Indexed Allocation

- 장점
  - 외부 조각 발생 X
  - Direct access 가능
- 단점
  - Small file의 경우 공간 낭비 (실제로 많은 file들이 small)
  - Too large file의 경우 하나의 block으로 index를 저장하기에 부족
    - 해결 방안
      1. linked scheme
      2. multi-level index



#### UNIX 파일 시스템의 구조

- 유닉스 파일 시스템의 중요 개념
  - Boot block
    - 부팅에 필요한 정보 (bootstrap loader)
  - Super block
    - 파일 시스템에 관한 총체적인 정보를 담고 있다
  - Inode
    - 파일 이름을 제외한 파일의 모든 메타 데이터를 저장
  - Data block
    - 파일의 실제 내용을 보관 (대부분의 메타 데이터가 Inode에 저장되어 있지만 file 이름은 directory에 저장되어 있음!!)



#### FAT (File-Allocation Table) File System

- Data block의 directory file에 메타데이터를 저장(index 포함) --> 다음 데이터로 갈 인덱스를 FAT라는 곳에 저장 --> Linked Allocation의 단점을 전부 극복 (데이터 손실 X, Reliability 개선)



#### Free-Space Management

- Bit map or Bit vector
  - Bit map은 부가적인 공간을 필요로 함
  - 연속적인 n개의 free block을 찾는데 효과적
- Linked list
  - 모든 free block들을 링크로 연결 (free list)
  - 연속적인 가용공간을 찾는 것은 쉽지 않다
  - 공간의 낭비가 없다
- Grouping
  - Index list 방법의 변형
  - 첫번째 free block이 n개의 pointer를 가짐
    - n-1 pointer는 free data block을 가리킴
    - 마지막 pointer가 가리키는 block은 또 다시 n pointer를 가짐
- Counting --> 연속적인 빈 블록을 찾기 위한 효율적인 방법!!
  - 프로그램들이 종종 여러 개의 연속적인 block을 할당하고 반납한다는 성질에 착안
  - (first free block, # of contiguous free blocks) 형태로 유지



#### Directory Implementation

- Linear list
  - <File name, File의 metadata>의 list
  - 구현이 간단
  - 디렉토리 내에 파일이 있는지 찾기 위해서는 linear search 필요 (time-consuming)
- Hash Table
  - linear list + hashing
  - Hash table은 file name을 이 파일의 linear list의 위치로 바꾸어줌
  - search time을 없앰
  - Collision 발생 가능

- File의 metadata의 보관 위치
  - 디렉토리 내에 직접 보관
  - 디렉토리에는 포인터를 두고 다른 곳에 보관
    - inode (UNIX), FAT (파일의 다음 위치 정보 보관)
- Long file name의 지원
  - <File name, File의 metadata>의 list에서 각 entry는 일반적으로 고정 크기
  - file name이 고정 크기의 entry 길이보다 길어지는 경우 entry의 마지막 부분에 이름의 뒷부분이 위치한 곳의 포인터를 두는 방법
  - 이름의 나머지 부분은 동일한 directory file의 일부에 존재



#### VFS and NFS

- Virtual File System (VFS)
  - 서로 다른 다양한 file system에 대해 동일한 시스템 콜 인터페이스(API)를 통해 접근할 수 있게 해주는 OS의 layer
- Network File System (NFS)
  - 분산 시스템에서는 네트워크를 통해 파일이 공유될 수 있음
  - NFS는 분산 환경에서의 대표적인 파일 공유 방법



#### Page Cache and Buffer Cache

- Page Cache

  - OS가 파일에 대한 정보를 모르기 때문에 Clock 알고리즘을 사용해야 함 (LRU, LFU 사용 불가)
  - Virtual memory의 paging system에서 사용하는 page frame을 caching의 관점에서 설명하는 용어
  - Memory-Mapped I/O를 쓰는 경우 file의 I/O에서도 page cache 사용

- Memory-Mapped I/O

  - File의 일부를 virtual memory에 mapping 시킴
  - 매핑시킨 영역에 대한 메모리 접근 연산은 파일의 입출력을 수행하게 함
  - 장점 : 이미 메모리에 올라와있는 내용에 대해서는 커널의 도움 없이 (=운영체제를 호출하지 않고) 자신의 메모리에 접근하듯이 읽어올 수 있다

- Buffer Cache

  - 파일시스템을 통한 I/O 연산은 처음 불러온다면 그 데이터를 buffer cache에 저장하고, 후속 요청시 메모리의 특정 영역인 buffer cache 사용

  - File 사용의 locality 활용

    - 한번 읽어온 block에 대한 후속 요청시 buffer cache에서 즉시 전달

  - 모든 프로세스가 공용으로 사용

  - replacement algorithm 필요 (LRU, LFU 등)

    Buffer Cache에 데이터를 쓰거나 읽을 때는 시스템콜을 통해 I/O 작업을 동반하므로 OS가 데이터에 대한 정보를 알고 있기 때문에 LRU, LFU 등을 쓸 수 있다.

- Unified Buffer Cache

  - 최근 OS에서는 기존의 buffer cache가 page cache에 통합됨
  - Page Cache 영역과 Buffer Cache 영역을 굳이 나누지 않고 필요하다면 메모리 영역을 필요한걸로 쓴다



#### Memory-Mapped I/O 와 Read/Write 시스템 콜의 차이점

- Memory-Mapped는 동일한 물리적 메모리 영역에 있는 데이터 파일을 각각의 가상 메모리 영역에 할당해서 쓰므로 동기화(Sychronization)문제가 생길 수 있지만, read/write 시스템 콜은 물리적 메모리 영역에 있는 데이터 파일을 복제(Copy)해서 가져오므로 동기화문제는 발생하지 않는다

---



### 9. Disk Management and Scheduling

#### Disk Structure

- Logical block
  - 디스크의 외부에서 보는 디스크의 단위 정보 저장 공간들
  - 주소를 가진 1차원 배열처럼 취급
  - 정보를 전송하는 최소 단위
- Sector
  - Logical block이 물리적인 디스크에 매핑된 위치
  - Sector 0는 최외곽 실린더의 첫 트랙에 있는 첫번째 섹터이다



#### Disk Management

- Physical Formatting (**Low-level formatting**)
  - 디스크를 컨트롤러가 읽고 쓸 수 있도록 섹터들로 나누는 과정
  - 각 섹터는 *header* + *실제 data*(보통 512 bytes) + *trailer*로 구성
  - header와 trailer는 sector number, ECC (Error-Correcting Code) 등의 정보가 저장되며 controller가 직접 접근 및 운영
- Partitioning
  - 디스크를 하나 이상의 실린더 그룹으로 나누는 과정
  - OS는 이것을 독립적 disk로 취급 (Logical disk)
- Logical Formatting
  - 파일시스템을 만드는 것
  - FAT, inode, free space 등의 구조 포함
- Booting
  - ROM(메모리 내 유일한 휘발성 X인 메모리, 아주 작음)에 있는 "small bootstrap loader"(부팅을 위한 아주 작은 로더)의 실행
  - sector 0 (boot block)을 load하여 실행
  - sector 0은 "full Bootstrap loader program"
  - OS를 디스크에서 load하여 실행



#### Disk Scheduling

- Access time의 구성
  - Seek time -> 거의 대부분의 시간 차지
    - 헤드를 해당 실린더로 움직이는데 걸리는 시간
  - Rotational latency
    - 헤드가 원하는 섹터에 도달하기까지 걸리는 회전지연시간
  - Transfer time
    - 실제 데이터의 전송 시간
- Disk bandwidth
  - 단위 시간 당 전송된 바이트의 수
- Disk Scheduling
  - Seek time을 최소화하는 것이 목표



#### Disk Scheduling Algorithm

- FCFS (First Come First Service)
- SSTF (Shortest Seek Time First)
  - 현재 위치에서 가장 가까운 헤드부터 처리
  - 문제점 : starvation
- SCAN (=Elevator Algorithm)
  - 가장 간단하지만 가장 획기적인 스케줄링
  - disk arm이 디스크의 한쪽 끝에서 다른쪽 끝으로 이동하며 가는 길목에 있는 모든 요청을 처리
  - 다른 한쪽 끝에 도달하면 역방향으로 이동하며 오는 길목에 있는 모든 요청을 처리하며 다시 반대쪽 끝으로 이동
  - 문제점 : 실린더 위치에 따라 대기 시간이 다르다
- C-SCAN (Circular-SCAN)
  - 헤드가 한쪽 끝에서 다른쪽 끝으로 이동하며 가는 길목에 있는 모든 요청을 처리
  - 다른쪽 끝에 도달했으면 요청을 처리하지 않고 곧바로 출발점으로 다시 이동
  - SCAN보다 균일한 대기 시간을 제공
- N-SCAN
  - SCAN의 변형 알고리즘
  - 일단 arm이 한 방향으로 움직이기 시작하면 그 시점 이후에 도착한 job은 되돌아올 때 service
- LOOK and C-LOOK
  - SCAN이나 C-SCAN은 헤드가 디스크 끝에서 끝으로 이동
  - LOOK과 C-LOOK은 헤드가 진행 중이다가 그 방향에 더 이상 기다리는 요청이 없으면 헤드의 이동방향을 즉시 반대로 이동



#### Disk-Scheduling Algorithm의 결정

- SCAN, C-SCAN 및 그 응용 알고리즘은 LOOJ, C-LOOK 등이 일반적으로 디스크 입출력이 많은 시스템에서 효율적인 것으로 알려져 있음
- File의 할당 방법에 따라 디스크 요청이 영향을 받음 (연속 할당인 경우 빠름)
- 디스크 스케줄링 알고리즘은 필요할 경우 다른 알고리즘으로 쉽게 교체할 수 있도록 OS와 별도의 모듈로 작성되는 것이 바람직하다



#### Swap-Space Management

- Disk를 사용하는 두 가지 이유
  - memory의 volatile(휘발성)한 특성 --> file system
  - 프로그램 실행을 위한 memory 공간 부족 --> swap space (swap area)
- Swap-space
  - Virtual memory system에서는 디스크를 memory의 연장 공간으로 사용
  - 파일시스템 내부에 둘 수도 있으나 별도 partition 사용이 일반적
    - 공간효율성보다는 속도 효율성이 우선!!
      (seek time이 대부분의 시간을 잡아 먹으므로 속도를 올리기 위해 상대적으로 대용량의 파일을 swap area에 올리는 것이 중요하고, 공간효율성은 어차피 사라질 메모리이기 때문에 덜 중요)
    - 일반 파일보다 훨씬 짧은 시간만 존재하고 자주 참조됨
    - 따라서, block의 크기 및 저장 방식이 일반 파일시스템과 다름



#### RAID (Redundant Array of Independent Disks)

- 여러 개의 디스크를 묶어서 사용
- RAID 사용 목적
  - 디스크 처리 속도 향상
    - 여러 디스크에 block의 내용을 분산 저장
    - 병렬적으로 읽어 옴 (interleaving, striping)
  - 신뢰성 (reliability) 향상
    - 동일 정보를 여러 디스크에 중복 저장
    - 하나의 디스크가 고장(failure)시 다른 디스크에서 읽어옴 (Mirroring, shadowing)
    - 단순한 중복 저장이 아니라 일부 디스크에 parity를 저장하여 공간의 효율성을 높일 수 있다
      (parity : 오류가 생긴지를 알아내고 복구할 수 잇을 정도의 중복저장만 가능하게 해주는 기법)



#### 질문

1. RAID(Redundant Array of Independent Disk)란 무엇이고, RAID의 목적에 대해 설명하시오.

   - 여러 개의 저장 장치를 묶어서 하나의 고용량/고성능 저장 장치처럼 사용하는 기술
   - 목적 : 디스크 처리 속도 향상, 안정성 향상

   

2. CPU 스케줄링을 하는 이유 (성능 척도)와 선점 스케줄링 중 생각나는 알고리즘에 대해 설명해보시오.

   - CPU의 이용률과 처리량을 증가시키고, 소요시간과 대기시간, 응답시간을 줄이기 위해서 사용

   - Round Robin(RR) : 각 프로세스에게 일정 시간만 할당하고 할당 시간이 끝나면 ready queue의 맨 뒤로 보낸다

     - 할당시간(q)이 크면 --> FCFS
     - 할당시간(q)가 작으면 --> context switch 오버헤드가 커진다
     - 일반적으로 SJF보다 average turnaround time(소요 시간)이 길지만 response time(응답 시간)은 짧다

     

3. 운영체제의 역할 4가지를 설명하시오.
   - 프로세스 관리 : CPU 스케줄링 등
   - 기억장치 관리 : 메모리 관리
   - 입출력장치 관리 : 상태 파악, I/O 스케줄링 등
   - 정보 관리 : 파일 관리



4. 스레드의 개념과 장점을 설명하시오.
   - 스레드는 한 프로세스 내에서 동작되는 여러 실행의 흐름을 의미한다.
   - 다중 스레드 사용의 장점
     - 반응성 (한 스레드가 막혀도 다른 스레드가 동작해서 ㄱㅊ)
     - 자원 공유 (한 프로세스를 수행하는 다중 스레드끼리 자원을 공유해서 빠른 처리, 병렬성 향상)
     - 경제성 (프로세스를 생성하고 프로세스를 스위칭하는 것보다 훨씬 빠름)
     - 유용성 (다른 프로세서를 사용하더라도 각 스레드는 병렬적으로 수행됨)



5. Process synchronization이 제대로 되지 않았을 때의 문제점과 해결 조건
   - 공유 데이터의 동시 접근으로 인해 데이터의 불일치 문제가 발생할 수 있다
   - synchronization을 해결하려면 Mutual Exclusion (상호 배제), Progress (진행), Bounded waiting (유한 대기)를 충족시켜야 한다
     - Mutual Exclusion (상호 배제)
       - 프로세스 Pi가 critical section 부분을 수행 중이면 다른 모든 프로세스들은 그들의 critical section에 들어가면 안된다
     - Progress (진행)
       - 아무도 critical section에 있지 않은 상태에서 critical section에 들어가고자 하는 프로세스가 있으면 critical section에 들어가게 해주어야 한다
     - Bounded waiting (유한 대기)
       - 프로세스가 critical section에 들어가려고 요청한 후부터 그 요청이 허용될 때까지 다른 프로세스들이 critical section에 들어가는 횟수에 한계가 있어야 한다



